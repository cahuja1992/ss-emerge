# --- General Experiment Settings ---
experiment_name: "Experiment2_SS_EMERGE_SEED_50_SSL"
description: "SS-EMERGE Self-Supervised on SEED with 50% labels"
phase: "finetune" # Always finetune phase after pretrain for SSL
dataset_name: "SEED"
num_classes: 3 

# --- Data Paths ---
data_root: "./data/SEED/"
train_data_path: "x_train_SEED.npy"
train_labels_path: "y_train_SEED.npy"
test_data_path: "x_test_SEED.npy"
test_labels_path: "y_test_SEED.npy"

# --- Model Architecture ---
model:
  model_type: "SS_EMERGE_Encoder"
  encoder:
    F_bands: 5
    D_spectral: 128
    C_channels: 62
    T_timesteps: 200 # Original SFREQ of dataset segments
    gat_out_channels: 256
    tcn_channels: [512, 512]
    tcn_kernel_size: 3
    tcn_dilations: [1, 2]
    dropout_prob: 0.5 
  classification_head:
    in_features: 512 
    num_classes: 3 
    dropout_prob: 0.5 

# --- Pretraining Settings ---
pretrain:
  epochs: 3288 # From thesis Table 6.1
  batch_size: 16 # P
  Q: 2 # Q
  temperature: 0.1
  learning_rate: 0.001
  save_interval: 500
  pretrained_model_dir: "./pretrained_models/Experiment2_SS_EMERGE_SEED_50_SSL/" 

# --- Finetuning Settings ---
finetune:
  epochs: 100 # From thesis Table 6.1
  batch_size: 256
  learning_rate: 0.001
  save_interval: 10
  finetuned_model_dir: "./finetuned_models/Experiment2_SS_EMERGE_SEED_50_SSL/" 
  label_proportion: 0.5 # <--- Key change for this experiment
  
# --- Evaluation Settings ---
evaluate:
  eval_batch_size: 32

# --- Hardware Settings ---
gpu: 0